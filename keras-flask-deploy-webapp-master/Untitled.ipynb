{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4486953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\DELL\\\\keras-flask-deploy-webapp-master'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ba1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Check http://127.0.0.1:5000/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import io\n",
    "\n",
    "# Flask\n",
    "from flask import Flask, redirect, url_for, request, render_template, Response, jsonify, redirect\n",
    "from werkzeug.utils import secure_filename\n",
    "from gevent.pywsgi import WSGIServer\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# Some utilites\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Some utilites\n",
    "import numpy as np\n",
    "from util import base64_to_pil\n",
    "\n",
    "\n",
    "# Declare a flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "\n",
    "# You can use pretrained model from Keras\n",
    "# Check https://keras.io/applications/\n",
    "# or https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
    "\n",
    "model_vgg16 = models.vgg16(pretrained=True)\n",
    "for param in model_vgg16.parameters():\n",
    "    param.requires_grad=True\n",
    "model_vgg16.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(4096, 512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.5),\n",
    "                      nn.Linear(512, 4))\n",
    "\n",
    "MODEL_PATH = 'C:/Users/DELL/keras-flask-deploy-webapp-master/models/model_vgg16 (3).pt'\n",
    "model_vgg16.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "print('Model loaded. Check http://127.0.0.1:5000/')\n",
    "\n",
    "class_index={0:'BrownSpot', 1: 'Healthy', 2:'Hispa', 3: 'LeafBlast'}\n",
    "\n",
    "def transform_image(image_bytes):\n",
    "    my_transforms = transforms.Compose([transforms.Resize(225),\n",
    "                                           transforms.CenterCrop(224),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                                [0.229, 0.224, 0.225])])\n",
    "    image = Image.open(io.BytesIO(image_bytes))\n",
    "    return my_transforms(image).unsqueeze(0)\n",
    "\n",
    "def get_prediction(image_bytes):\n",
    "    tensor = transform_image(image_bytes=image_bytes)\n",
    "    outputs = model_vgg16.forward(tensor)\n",
    "    _, y_hat = torch.max(outputs,1)\n",
    "    y_hat=y_hat.numpy()\n",
    "    #print(outputs)\n",
    "    predicted_idx = y_hat.item()\n",
    "    return predicted_idx, class_index[predicted_idx]\n",
    "\n",
    "    #probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    #conf, classes =  torch.max(probs, 1)\n",
    "    #print(probs)\n",
    "    #return predicted_idx ,class_index[predicted_idx]\n",
    "    #return conf.item(), class_index[classes.item()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def index():\n",
    "    # Main page\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    if request.method == 'POST':\n",
    "        img = base64_to_pil(request.json)\n",
    "\n",
    "        imgByteArr = io.BytesIO()\n",
    "        # image.save expects a file as a argument, passing a bytes io ins\n",
    "        img.save(imgByteArr, format= img.format)\n",
    "        # Turn the BytesIO object back into a bytes object\n",
    "        imgByteArr = imgByteArr.getvalue()\n",
    "        print(imgByteArr)\n",
    "        #file = request.files['file']\n",
    "        #img_bytes = file.read()\n",
    "        class_id, class_name = get_prediction(image_bytes=imgByteArr)\n",
    "        return jsonify(class_id = class_id, class_name = class_name)\n",
    "    return None\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run()\n",
    "\n",
    "    # app.run(port=5002, threaded=False)\n",
    "\n",
    "    # Serve the app with gevent\n",
    "    http_server = WSGIServer(('0.0.0.0', 5000), app)\n",
    "    http_server.serve_forever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b855d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
