{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:57:35.531516Z","iopub.execute_input":"2022-08-16T12:57:35.532190Z","iopub.status.idle":"2022-08-16T12:57:35.538605Z","shell.execute_reply.started":"2022-08-16T12:57:35.532156Z","shell.execute_reply":"2022-08-16T12:57:35.537422Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Imports\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nimport torchvision\nfrom torchvision import datasets, transforms, models\nfrom torch.autograd import Variable\nfrom torch.utils.data.sampler import SubsetRandomSampler","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:57:37.085713Z","iopub.execute_input":"2022-08-16T12:57:37.086120Z","iopub.status.idle":"2022-08-16T12:57:39.115662Z","shell.execute_reply.started":"2022-08-16T12:57:37.086092Z","shell.execute_reply":"2022-08-16T12:57:39.114465Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#Define the data directory\ndata_dir = '../input/rice-diseases-image-dataset/LabelledRice/Labelled/'","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:57:39.119645Z","iopub.execute_input":"2022-08-16T12:57:39.120980Z","iopub.status.idle":"2022-08-16T12:57:39.125675Z","shell.execute_reply.started":"2022-08-16T12:57:39.120939Z","shell.execute_reply":"2022-08-16T12:57:39.124476Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from glob import glob\nimages = glob(os.path.join(data_dir, '*/*.jpg'))\ntot_images = len(images)\nprint('Total images:', tot_images)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T01:53:06.352985Z","iopub.execute_input":"2022-08-16T01:53:06.353349Z","iopub.status.idle":"2022-08-16T01:53:07.555250Z","shell.execute_reply.started":"2022-08-16T01:53:06.353319Z","shell.execute_reply":"2022-08-16T01:53:07.554206Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tot_images = 3355\nim_cnt = []\nclass_names = []\nprint('{:18s}'.format('Class'), end='')\nprint('Count')\nprint('-' * 24)\nfor folder in os.listdir(os.path.join(data_dir)):\n    folder_num = len(os.listdir(os.path.join(data_dir, folder)))\n    im_cnt.append(folder_num)\n    class_names.append(folder)\n    print('{:20s}'.format(folder), end=' ')\n    print(folder_num)\n    if (folder_num < tot_images):\n        tot_images = folder_num\n        folder_num = folder\n        \nnum_classes = len(class_names)\nprint('Total number of classes: {}'.format(num_classes))\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T01:53:11.927792Z","iopub.execute_input":"2022-08-16T01:53:11.928151Z","iopub.status.idle":"2022-08-16T01:53:11.940325Z","shell.execute_reply.started":"2022-08-16T01:53:11.928122Z","shell.execute_reply":"2022-08-16T01:53:11.939238Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Define transforms for the training and validation sets\ndata_transforms ={\n    \"train_transforms\": transforms.Compose([transforms.Resize(224),\n                                           transforms.RandomRotation(30),\n                                           transforms.RandomResizedCrop(224), \n                                           transforms.RandomHorizontalFlip(), \n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406], \n                                                                [0.229, 0.224, 0.225])]),\n   \"valid_transforms\": transforms.Compose([transforms.Resize(225),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])]), \n    \"test_transforms\": transforms.Compose([transforms.Resize(225),\n                                           transforms.CenterCrop(224),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize([0.485, 0.456, 0.406],\n                                                                [0.229, 0.224, 0.225])])\n}","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:07.591361Z","iopub.execute_input":"2022-08-16T12:58:07.591971Z","iopub.status.idle":"2022-08-16T12:58:07.603184Z","shell.execute_reply.started":"2022-08-16T12:58:07.591937Z","shell.execute_reply":"2022-08-16T12:58:07.602198Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Split the dataset into train, validation and test\ntrain_data = 0.8\nvalid_data = 0.1\ntest_data = 0.1\n\n# Load the datasets with ImageFolder\ntrain_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])#loading dataset\nvalid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\ntest_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"test_transforms\"])\n\n# Obtain training indices that will be used for validation and test\nnum_train = len(train_data)\nindices = list(range(num_train))\n# np.random.shuffle(indices)\ntrain_count = int(0.8*num_train)\nvalid_count = int(0.1*num_train)\ntest_count = num_train - train_count - valid_count\ntrain_idx = indices[:train_count]\nvalid_idx = indices[train_count:train_count+valid_count]\ntest_idx = indices[train_count+valid_count:]\n\nprint(len(train_idx), len(valid_idx), len(test_idx))\nprint(\"Training\", train_count, np.sum(len(train_idx)/num_train))\nprint(\"Validation\", valid_count, np.sum(len(valid_idx)/num_train))\nprint(\"Test\", test_count, np.sum(len(test_idx)/num_train))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:11.901707Z","iopub.execute_input":"2022-08-16T12:58:11.902701Z","iopub.status.idle":"2022-08-16T12:58:15.310578Z","shell.execute_reply.started":"2022-08-16T12:58:11.902654Z","shell.execute_reply":"2022-08-16T12:58:15.309507Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define a custom sampler for the dataset loader avoiding recreating the dataset (just creating a new loader for each different sampling)\ntrain_sampler = SubsetRandomSampler(train_idx)\nvalid_sampler = SubsetRandomSampler(valid_idx)\ntest_sampler = SubsetRandomSampler(test_idx)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:15.312587Z","iopub.execute_input":"2022-08-16T12:58:15.313241Z","iopub.status.idle":"2022-08-16T12:58:15.318386Z","shell.execute_reply.started":"2022-08-16T12:58:15.313204Z","shell.execute_reply":"2022-08-16T12:58:15.317440Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the dataloaders using the image datasets. Dataloader is used to load our data in batches\ntrainloader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\nvalidloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, sampler = valid_sampler)\ntestloader = torch.utils.data.DataLoader(test_data, batch_size = 32, sampler = test_sampler)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:15.829099Z","iopub.execute_input":"2022-08-16T12:58:15.829962Z","iopub.status.idle":"2022-08-16T12:58:15.836283Z","shell.execute_reply.started":"2022-08-16T12:58:15.829915Z","shell.execute_reply":"2022-08-16T12:58:15.835198Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5 #unnormalize\n    plt.imshow(np.transpose(img, (1,2,0))) #convert tensor image type to numpy image type for visualization","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:56.943475Z","iopub.execute_input":"2022-08-16T12:58:56.944193Z","iopub.status.idle":"2022-08-16T12:58:56.949619Z","shell.execute_reply.started":"2022-08-16T12:58:56.944157Z","shell.execute_reply":"2022-08-16T12:58:56.948514Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"classes=['LeafBlast', 'BrownSpot', 'Healthy', 'Hispa']","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:58.580648Z","iopub.execute_input":"2022-08-16T12:58:58.581484Z","iopub.status.idle":"2022-08-16T12:58:58.586159Z","shell.execute_reply.started":"2022-08-16T12:58:58.581450Z","shell.execute_reply":"2022-08-16T12:58:58.584830Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Visualize some sample data\n#Obtain one batch of training images\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimages = images.numpy() #convert images to numpy for display\n\n#Plot the images in the batch, along with corresponding labels\nfig = plt.figure(figsize=(25,4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, int(20/2), idx+1, xticks=[], yticks=[])\n    imshow(images[idx])\n    #ax.set_title(str(labels[idx].item()))\n    ax.set_title(classes[labels[idx]])","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:58:59.228421Z","iopub.execute_input":"2022-08-16T12:58:59.229443Z","iopub.status.idle":"2022-08-16T12:59:13.833825Z","shell.execute_reply.started":"2022-08-16T12:58:59.229397Z","shell.execute_reply":"2022-08-16T12:59:13.832345Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# googlenet","metadata":{}},{"cell_type":"code","source":"# Specify model architecture\n# Load the pretrained model from pytorch's library and stored it in model_transfer\nmodel_transfer = models.googlenet(pretrained=True)\n\n# Check if GPU is available\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    model_transfer = model_transfer.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T19:46:14.258768Z","iopub.execute_input":"2022-08-15T19:46:14.259078Z","iopub.status.idle":"2022-08-15T19:46:18.163166Z","shell.execute_reply.started":"2022-08-15T19:46:14.259050Z","shell.execute_reply":"2022-08-15T19:46:18.162172Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#print the model to see all the layers\nprint(model_transfer)","metadata":{"execution":{"iopub.status.busy":"2022-08-13T22:41:03.313451Z","iopub.execute_input":"2022-08-13T22:41:03.313854Z","iopub.status.idle":"2022-08-13T22:41:03.322034Z","shell.execute_reply.started":"2022-08-13T22:41:03.313816Z","shell.execute_reply":"2022-08-13T22:41:03.320953Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Lets read the fully connected layer\nprint(model_transfer.fc.in_features)\nprint(model_transfer.fc.out_features)","metadata":{"execution":{"iopub.status.busy":"2022-08-13T22:41:03.323331Z","iopub.execute_input":"2022-08-13T22:41:03.324000Z","iopub.status.idle":"2022-08-13T22:41:03.334615Z","shell.execute_reply.started":"2022-08-13T22:41:03.323966Z","shell.execute_reply":"2022-08-13T22:41:03.330631Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"for param in model_transfer.parameters():\n    param.requires_grad=True","metadata":{"execution":{"iopub.status.busy":"2022-08-13T22:41:27.496553Z","iopub.execute_input":"2022-08-13T22:41:27.496989Z","iopub.status.idle":"2022-08-13T22:41:27.503531Z","shell.execute_reply.started":"2022-08-13T22:41:27.496953Z","shell.execute_reply":"2022-08-13T22:41:27.502212Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Define n_inputs takes the same number of inputs from pre-trained model\nn_inputs = model_transfer.fc.in_features #refer to the fully connected layer only\n\n# Add last linear layer (n_inputs -> 4 classes). In this case the ouput is 4 classes\n# New layer automatically has requires_grad = True\nlast_layer = nn.Linear(n_inputs, len(classes))\n\nmodel_transfer.fc = last_layer\n\n# If GPU is available, move the model to GPU\nif use_cuda:\n    model_transfer = model_transfer.cuda()\n  \n# Check to see the last layer produces the expected number of outputs\nprint(model_transfer.fc.out_features)","metadata":{"execution":{"iopub.status.busy":"2022-08-13T22:41:27.917754Z","iopub.execute_input":"2022-08-13T22:41:27.918466Z","iopub.status.idle":"2022-08-13T22:41:27.929922Z","shell.execute_reply.started":"2022-08-13T22:41:27.918429Z","shell.execute_reply":"2022-08-13T22:41:27.928437Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Specify loss function and optimizer\ncriterion_transfer = nn.CrossEntropyLoss()\noptimizer_transfer = optim.SGD(model_transfer.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2022-08-13T22:41:59.023769Z","iopub.execute_input":"2022-08-13T22:41:59.024153Z","iopub.status.idle":"2022-08-13T22:41:59.031687Z","shell.execute_reply.started":"2022-08-13T22:41:59.024120Z","shell.execute_reply":"2022-08-13T22:41:59.030594Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# vgg","metadata":{}},{"cell_type":"code","source":"# Specify model architecture\n# Load the pretrained model from pytorch's library and stored it in model_transfer\nmodel_vgg16 = models.vgg16(pretrained=True)\n\n# Check if GPU is available\nuse_cuda = torch.cuda.is_available()\nif use_cuda:\n    model_vgg16 = model_vgg16.cuda()","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:59:13.835175Z","iopub.execute_input":"2022-08-16T12:59:13.835510Z","iopub.status.idle":"2022-08-16T12:59:27.891635Z","shell.execute_reply.started":"2022-08-16T12:59:13.835474Z","shell.execute_reply":"2022-08-16T12:59:27.890641Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#print the model to see all the layers\nprint(model_vgg16)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:59:27.893218Z","iopub.execute_input":"2022-08-16T12:59:27.893594Z","iopub.status.idle":"2022-08-16T12:59:27.899123Z","shell.execute_reply.started":"2022-08-16T12:59:27.893553Z","shell.execute_reply":"2022-08-16T12:59:27.898165Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"for param in model_vgg16.parameters():\n    param.requires_grad=True","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:59:27.902124Z","iopub.execute_input":"2022-08-16T12:59:27.902799Z","iopub.status.idle":"2022-08-16T12:59:27.911349Z","shell.execute_reply.started":"2022-08-16T12:59:27.902763Z","shell.execute_reply":"2022-08-16T12:59:27.910468Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"\nmodel_vgg16.classifier[6] = nn.Sequential(\n                      nn.Linear(4096, 512), \n                      nn.ReLU(), \n                      nn.Dropout(0.5),\n                      nn.Linear(512, 4))\n\n# If GPU is available, move the model to GPU\nif use_cuda:\n    model_vgg16 = model_vgg16.cuda()\n  \n\n # Observe that all parameters are being optimized\ncriterion_vgg = nn.CrossEntropyLoss()\n\noptimizer_vgg = optim.SGD(model_vgg16.parameters(), lr=0.001, momentum=0.9)\n\n\n\n# Check to see the last layer produces the expected number of outputs\nprint(model_vgg16)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:59:27.913118Z","iopub.execute_input":"2022-08-16T12:59:27.913456Z","iopub.status.idle":"2022-08-16T12:59:27.943334Z","shell.execute_reply.started":"2022-08-16T12:59:27.913423Z","shell.execute_reply":"2022-08-16T12:59:27.942179Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# training","metadata":{}},{"cell_type":"code","source":"# Train the model\ndef train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n    '''returns trained model'''\n    # Initialize tracker for minimum validation loss\n    valid_loss_min = np.inf\n  \n    for epoch in range(1, n_epochs+1):\n        # In the training loop, I track down the loss\n        # Initialize variables to monitor training and validation loss\n        train_loss = 0.0\n        valid_loss = 0.0\n    \n        # Model training\n        model.train()\n\n        for batch_idx, (data,target) in enumerate(trainloader):\n            # 1st step: Move to GPU\n            if use_cuda:\n                data,target = data.cuda(), target.cuda()\n\n      \n            # Then, clear (zero out) the gradient of all optimized variables\n            optimizer.zero_grad()\n            # Forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # Perform the Cross Entropy Loss. Calculate the batch loss.\n            loss = criterion(output, target)\n            # Backward pass: compute gradient of the loss with respect to model parameters\n            loss.backward()\n            # Perform optimization step (parameter update)\n            optimizer.step()\n            # Record the average training loss\n            train_loss = train_loss + ((1/ (batch_idx + 1 ))*(loss.data-train_loss))\n            print('epoch',epoch,'batch',batch_idx)\n      \n        # Model validation\n        model.eval()\n        \n        for batch_idx, (data,target) in enumerate(validloader):\n            # Move to GPU\n            if use_cuda:\n                data, target = data.cuda(), target.cuda()\n            # Update the average validation loss\n            # Forward pass: compute predicted outputs by passing inputs to the model\n            output = model(data)\n            # Calculate the batch loss\n            loss = criterion(output, target)\n            # Update the average validation loss\n            valid_loss = valid_loss + ((1/ (batch_idx +1)) * (loss.data - valid_loss))\n      \n        # print training/validation stats\n        print('Epoch: {} \\tTraining Loss: {:.5f} \\tValidation Loss: {:.5f}'.format(\n            epoch,\n            train_loss,\n            valid_loss))\n    \n        # Save the model if validation loss has decreased\n        if valid_loss <= valid_loss_min:\n            print('Validation loss decreased ({:.5f} --> {:.5f}). Saving model ...'.format(\n                  valid_loss_min,\n                  valid_loss))\n            torch.save(model.state_dict(), save_path)\n            valid_loss_min = valid_loss\n  \n    # Return trained model\n    return model\n\n# Define loaders transfer\nloaders_transfer = {'train': trainloader,\n                    'valid': validloader,\n                    'test': testloader}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-16T12:59:27.944891Z","iopub.execute_input":"2022-08-16T12:59:27.945366Z","iopub.status.idle":"2022-08-16T12:59:27.957935Z","shell.execute_reply.started":"2022-08-16T12:59:27.945329Z","shell.execute_reply":"2022-08-16T12:59:27.956935Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### googlenet  training","metadata":{}},{"cell_type":"code","source":"# Train the model\nmodel_transfer = train(50, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')","metadata":{"execution":{"iopub.status.busy":"2022-08-13T23:12:02.446821Z","iopub.execute_input":"2022-08-13T23:12:02.447184Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the model that got the best validation accuracy\nmodel_transfer.load_state_dict(torch.load('model_transfer.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-08-14T06:27:07.141108Z","iopub.execute_input":"2022-08-14T06:27:07.141800Z","iopub.status.idle":"2022-08-14T06:27:07.238249Z","shell.execute_reply.started":"2022-08-14T06:27:07.141762Z","shell.execute_reply":"2022-08-14T06:27:07.237259Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"### vgg16 training","metadata":{}},{"cell_type":"code","source":"model_vgg16 = train(50, loaders_transfer, model_vgg16, optimizer_vgg, criterion_vgg, use_cuda, 'model_vgg16.pt')","metadata":{"execution":{"iopub.status.busy":"2022-08-16T13:39:00.444569Z","iopub.execute_input":"2022-08-16T13:39:00.445148Z","iopub.status.idle":"2022-08-16T20:52:45.078108Z","shell.execute_reply.started":"2022-08-16T13:39:00.445114Z","shell.execute_reply":"2022-08-16T20:52:45.076946Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"model_vgg16.load_state_dict(torch.load('./model_vgg16.pt'))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T20:53:25.280973Z","iopub.execute_input":"2022-08-16T20:53:25.281622Z","iopub.status.idle":"2022-08-16T20:53:25.759778Z","shell.execute_reply.started":"2022-08-16T20:53:25.281574Z","shell.execute_reply":"2022-08-16T20:53:25.758720Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# testing","metadata":{}},{"cell_type":"code","source":"def test(loaders, model, criterion, use_cuda):\n\n    # monitor test loss and accuracy\n    test_loss = 0.\n    correct = 0.\n    total = 0.\n\n    model.eval() #set model into evaluation/testing mode. It turns of drop off layer\n    #Iterating over test data\n    for batch_idx, (data, target) in enumerate(loaders['test']):\n        # move to GPU\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        output = model(data)\n        # calculate the loss\n        loss = criterion(output, target)\n        # update average test loss \n        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n        # convert output probabilities to predicted class\n        pred = output.data.max(1, keepdim=True)[1]\n        # compare predictions to \n        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n        total += data.size(0)\n            \n    print('Test Loss: {:.6f}\\n'.format(test_loss))\n\n    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n        100. * correct / total, correct, total))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T20:53:25.763418Z","iopub.execute_input":"2022-08-16T20:53:25.764083Z","iopub.status.idle":"2022-08-16T20:53:25.774289Z","shell.execute_reply.started":"2022-08-16T20:53:25.764048Z","shell.execute_reply":"2022-08-16T20:53:25.773001Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"### testing googlenet","metadata":{}},{"cell_type":"code","source":"# call test function    \ntest(loaders_transfer, model_transfer, criterion_transfer, use_cuda)","metadata":{"execution":{"iopub.status.busy":"2022-08-14T06:27:12.013798Z","iopub.execute_input":"2022-08-14T06:27:12.014154Z","iopub.status.idle":"2022-08-14T06:27:46.646249Z","shell.execute_reply.started":"2022-08-14T06:27:12.014124Z","shell.execute_reply":"2022-08-14T06:27:46.645290Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#Obtain one batch of test images\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimages.numpy\n\n#Move model inputs to cuda, if GPU available\nif use_cuda:\n    images = images.cuda()\n    \n#Get sample outputs\noutput= model_transfer(images)\n\n#Convert output probabilities to predicted class\n_,preds_tensor = torch.max(output,1)\npreds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n\n#Plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(30,4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images.cpu()[idx], (1,2,0)))\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]],classes[labels[idx]]),\n                color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### testing vgg","metadata":{}},{"cell_type":"code","source":"test(loaders_transfer, model_vgg16 , criterion_vgg, use_cuda)","metadata":{"execution":{"iopub.status.busy":"2022-08-16T20:53:25.776901Z","iopub.execute_input":"2022-08-16T20:53:25.778323Z","iopub.status.idle":"2022-08-16T20:54:05.167480Z","shell.execute_reply.started":"2022-08-16T20:53:25.778268Z","shell.execute_reply":"2022-08-16T20:54:05.166199Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#Obtain one batch of test images\ndataiter = iter(testloader)\nimages, labels = dataiter.next()\nimages.numpy\n\n#Move model inputs to cuda, if GPU available\nif use_cuda:\n    images = images.cuda()\n    \n#Get sample outputs\noutput= model_vgg16(images)\n\n#Convert output probabilities to predicted class\n_,preds_tensor = torch.max(output,1)\npreds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n\n#Plot the images in the batch, along with predicted and true labels\nfig = plt.figure(figsize=(30,4))\nfor idx in np.arange(20):\n    ax = fig.add_subplot(2,int(20/2), idx+1, xticks=[], yticks=[])\n    plt.imshow(np.transpose(images.cpu()[idx], (1,2,0)))\n    ax.set_title(\"{} ({})\".format(classes[preds[idx]],classes[labels[idx]]),\n                color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))","metadata":{"execution":{"iopub.status.busy":"2022-08-16T21:02:06.552574Z","iopub.execute_input":"2022-08-16T21:02:06.553238Z","iopub.status.idle":"2022-08-16T21:02:11.728259Z","shell.execute_reply.started":"2022-08-16T21:02:06.553205Z","shell.execute_reply":"2022-08-16T21:02:11.727350Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torchvision\nimport pickle\nPATH = \"./model_transfer.pt\"\npytorch_model = torch.load(PATH)\n\noutfile = \"export.pkl\"\nwith open(outfile, 'wb') as pickle_file:\n    pickle.dump(pytorch_model, pickle_file)","metadata":{"execution":{"iopub.status.busy":"2022-08-14T07:09:14.045678Z","iopub.execute_input":"2022-08-14T07:09:14.046094Z","iopub.status.idle":"2022-08-14T07:09:14.229359Z","shell.execute_reply.started":"2022-08-14T07:09:14.046058Z","shell.execute_reply":"2022-08-14T07:09:14.228342Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}